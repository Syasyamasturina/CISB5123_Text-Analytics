{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5152c2b-bef5-414e-a079-54b18cc11c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\syasy\\anaconda3\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\syasy\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (4.13.5)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from selenium) (2026.1.4)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.1)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\syasy\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ertifi (C:\\Users\\syasy\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ertifi (C:\\Users\\syasy\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ertifi (C:\\Users\\syasy\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium pandas beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50491cbe-6ce9-43dd-b278-b6d0b41fb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping page 1\n",
      "Visible reviews detected: 25\n",
      "\n",
      "Scraping page 2\n",
      "Visible reviews detected: 25\n",
      "\n",
      "Scraping page 3\n",
      "Visible reviews detected: 25\n",
      "\n",
      "Scraping page 4\n",
      "Visible reviews detected: 25\n",
      "\n",
      "Scraping page 5\n",
      "Visible reviews detected: 25\n",
      "\n",
      "Scraping completed and saved to newegg_reviews_page1_to_5.csv\n"
     ]
    }
   ],
   "source": [
    "# Student 1\n",
    "# Name: Nur Syasya Masturina binti Ibrahim\n",
    "# Student ID: IS01083881\n",
    "\n",
    "# Student 2\n",
    "# Name: Irdina Nadiah Binti Mohd Rizal\n",
    "# Student ID: IS01083874\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "url = \"https://www.newegg.com/gigabyte-gs27qa-sa-27-qhd-180-hz-super-speed-ips-black/p/N82E16824012083\"\n",
    "driver.get(url)\n",
    "\n",
    "#scroll page until review tab \n",
    "for _ in range(10):\n",
    "    driver.execute_script(\"window.scrollBy(0, 800);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "#click reviews tab\n",
    "review_tab = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(),'Reviews')]\"))\n",
    ")\n",
    "driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "\n",
    "#wait until the review tab section loads \n",
    "wait.until(\n",
    "    EC.presence_of_element_located(\n",
    "        (By.XPATH, \"//div[contains(@class,'comments-cell')]\")\n",
    "    )\n",
    ")\n",
    "\n",
    "review_names = []\n",
    "review_dates = []\n",
    "review_contents = []\n",
    "\n",
    "#scrape page function\n",
    "def scrape_current_page():\n",
    "    reviews = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//div[contains(@class,'comments-cell') and contains(@class,'is-active')]\"\n",
    "    )\n",
    "    #shows only visible reviews\n",
    "    print(\"Visible reviews detected:\", len(reviews))\n",
    "\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            #reviewer's name\n",
    "            name = review.find_element(By.CLASS_NAME, \"comments-name\").text\n",
    "        except:\n",
    "            name = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            #date of review\n",
    "            date_elements = review.find_elements(By.CLASS_NAME, \"comments-text\")\n",
    "            date = date_elements[-1].text\n",
    "        except:\n",
    "            date = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            #content of review\n",
    "            content = review.find_element(By.CLASS_NAME, \"comments-content\").text\n",
    "        except:\n",
    "            content = \"N/A\"\n",
    "\n",
    "        review_names.append(name)\n",
    "        review_dates.append(date)\n",
    "        review_contents.append(content)\n",
    "\n",
    "#scrape review from page 1 to 5\n",
    "for page in range(1, 6):\n",
    "\n",
    "    print(f\"\\nScraping page {page}\")\n",
    "\n",
    "    #wait for the review page number to active\n",
    "    wait.until(\n",
    "        EC.presence_of_element_located(\n",
    "            (By.XPATH, f\"//a[text()='{page}' and contains(@class,'active')]\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #call scrape page function\n",
    "    scrape_current_page()\n",
    "\n",
    "    if page < 5:\n",
    "        next_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//a[text()='{page+1}']\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "        #wait until next review page becomes active\n",
    "        wait.until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, f\"//a[text()='{page+1}' and contains(@class,'active')]\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#save to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"Reviewer Name\": review_names,\n",
    "    \"Review Date\": review_dates,\n",
    "    \"Review Content\": review_contents\n",
    "})\n",
    "\n",
    "df.to_csv(\"newegg_reviews_page1_to_5.csv\", index=False)\n",
    "\n",
    "print(\"\\nScraping completed and saved to newegg_reviews_page1_to_5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
